{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "تحميل المكتبات"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from future.utils import iteritems\n",
    "from builtins import range\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import pairwise_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "عمل دالة المسافة لاستخدامها"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist1(a, b):\n",
    "    return np.linalg.norm(a - b)\n",
    "def dist2(a, b):\n",
    "    return 1 - a.dot(b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "dist, metric = dist2, 'cosine'\n",
    "# dist, metric = dist1, 'euclidean'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "عمل دالة لتنفيذ عملية الطرح"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_analogies(w1, w2, w3):\n",
    "    for w in (w1, w2, w3):\n",
    "        if w not in word2vec:\n",
    "            print(\"%s not in dictionary\" % w)\n",
    "            return\n",
    "\n",
    "    king = word2vec[w1]\n",
    "    man = word2vec[w2]\n",
    "    woman = word2vec[w3]\n",
    "    v0 = king - man + woman\n",
    "\n",
    "    min_dist = float('inf')\n",
    "    best_word = ''\n",
    "    for word, v1 in iteritems(word2vec):\n",
    "        if word not in (w1, w2, w3):\n",
    "            d = dist(v0, v1)\n",
    "            if d < min_dist:\n",
    "                min_dist = d\n",
    "                best_word = word\n",
    "    print(w1, \"-\", w2, \"=\", best_word, \"-\", w3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "نفس الدالة السابقة بطريقة اسرع"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_analogies(w1, w2, w3):\n",
    "    for w in (w1, w2, w3):\n",
    "        if w not in word2vec:\n",
    "            print(\"%s not in dictionary\" % w)\n",
    "            return\n",
    "\n",
    "    king = word2vec[w1]\n",
    "    man = word2vec[w2]\n",
    "    woman = word2vec[w3]\n",
    "    v0 = king - man + woman\n",
    "\n",
    "    distances = pairwise_distances(v0.reshape(1, D),\n",
    "                                   embedding, metric=metric).reshape(V)\n",
    "    idxs = distances.argsort()[:4]\n",
    "    for idx in idxs:\n",
    "        word = idx2word[idx]\n",
    "        if word not in (w1, w2, w3): \n",
    "            best_word = word\n",
    "            break\n",
    "\n",
    "    print(w1, \"-\", w2, \"=\", best_word, \"-\", w3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "عمل دالة لاختيار الكلمات الاقرب"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_neighbors(w, n=5):\n",
    "    if w not in word2vec:\n",
    "        print(\"%s not in dictionary:\" % w)\n",
    "        return\n",
    "\n",
    "    v = word2vec[w]\n",
    "    distances = pairwise_distances(v.reshape(1, D),\n",
    "                                   embedding, metric=metric).reshape(V)\n",
    "    idxs = distances.argsort()[1:n+1]\n",
    "    print(\"neighbors of: %s\" % w)\n",
    "    for idx in idxs:\n",
    "        print(\"\\t%s\" % idx2word[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "قراءة البيانات "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word vectors...\n",
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "print('Loading word vectors...')\n",
    "word2vec = {}\n",
    "embedding = []\n",
    "idx2word = []\n",
    "\n",
    "with open(r'E:\\Machine Learning\\NLP\\0 Data\\GloVe English\\glove.6B.50d.txt', encoding='utf-8') as f:\n",
    "  # is just a space-separated text file in the format:\n",
    "  # word vec[0] vec[1] vec[2] ...\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vec = np.asarray(values[1:], dtype='float32')\n",
    "        word2vec[word] = vec\n",
    "        embedding.append(vec)\n",
    "        idx2word.append(word)\n",
    "print('Found %s word vectors.' % len(word2vec))\n",
    "embedding = np.array(embedding)\n",
    "V, D = embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 50)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V, D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "الاطلاع علي البيانات"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word the   ,   with Vecs     [ 0.418       0.24968    -0.41242     0.1217      0.34527    -0.044457\n",
      " -0.49688    -0.17862    -0.00066023 -0.6566    ]\n",
      "word ,   ,   with Vecs     [ 0.013441  0.23682  -0.16899   0.40951   0.63812   0.47709  -0.42852\n",
      " -0.55641  -0.364    -0.23938 ]\n",
      "word .   ,   with Vecs     [ 0.15164  0.30177 -0.16763  0.17684  0.31719  0.33973 -0.43478 -0.31086\n",
      " -0.44999 -0.29486]\n",
      "word of   ,   with Vecs     [ 0.70853  0.57088 -0.4716   0.18048  0.54449  0.72603  0.18157 -0.52393\n",
      "  0.10381 -0.17566]\n",
      "word to   ,   with Vecs     [ 0.68047  -0.039263  0.30186  -0.17792   0.42962   0.032246 -0.41376\n",
      "  0.13228  -0.29847  -0.085253]\n",
      "word and   ,   with Vecs     [ 0.26818   0.14346  -0.27877   0.016257  0.11384   0.69923  -0.51332\n",
      " -0.47368  -0.33075  -0.13834 ]\n",
      "word in   ,   with Vecs     [ 0.33042   0.24995  -0.60874   0.10923   0.036372  0.151    -0.55083\n",
      " -0.074239 -0.092307 -0.32821 ]\n",
      "word a   ,   with Vecs     [ 0.21705  0.46515 -0.46757  0.10082  1.0135   0.74845 -0.53104 -0.26256\n",
      "  0.16812  0.13182]\n",
      "word \"   ,   with Vecs     [ 0.25769   0.45629  -0.76974  -0.37679   0.59272  -0.063527  0.20545\n",
      " -0.57385  -0.29009  -0.13662 ]\n",
      "word 's   ,   with Vecs     [ 0.23727  0.40478 -0.20547  0.58805  0.65533  0.32867 -0.81964 -0.23236\n",
      "  0.27428  0.24265]\n",
      "word for   ,   with Vecs     [ 0.15272   0.36181  -0.22168   0.066051  0.13029   0.37075  -0.75874\n",
      " -0.44722   0.22563   0.10208 ]\n",
      "word -   ,   with Vecs     [-0.16768  1.2151   0.49515  0.26836 -0.4585  -0.23311 -0.52822 -1.3557\n",
      "  0.16098  0.37691]\n",
      "word that   ,   with Vecs     [ 0.88387  -0.14199   0.13566   0.098682  0.51218   0.49138  -0.47155\n",
      " -0.30742   0.01963   0.12686 ]\n",
      "word on   ,   with Vecs     [ 0.30045   0.25006  -0.16692   0.1923    0.026921 -0.079486 -0.91383\n",
      " -0.1974   -0.053413 -0.40846 ]\n",
      "word is   ,   with Vecs     [ 0.6185     0.64254   -0.46552    0.3757     0.74838    0.53739\n",
      "  0.0022239 -0.60577    0.26408    0.11703  ]\n",
      "word was   ,   with Vecs     [ 0.086888 -0.19416  -0.24267  -0.33391   0.56731   0.39783  -0.97809\n",
      "  0.03159  -0.61469  -0.31406 ]\n",
      "word said   ,   with Vecs     [ 0.38973 -0.2121   0.51837  0.80136  1.0336  -0.27784 -0.84525 -0.25333\n",
      "  0.12586 -0.90342]\n",
      "word with   ,   with Vecs     [ 0.25616   0.43694  -0.11889   0.20345   0.41959   0.85863  -0.60344\n",
      " -0.31835  -0.6718    0.003984]\n",
      "word he   ,   with Vecs     [-0.20092  -0.060271 -0.61766  -0.8444    0.5781    0.14671  -0.86098\n",
      "  0.6705   -0.86556  -0.18234 ]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for a,b in word2vec.items() : \n",
    "    i+=1\n",
    "    if i==20 : break\n",
    "    print(f'word {a}   ,   with Vecs     {b[:10]}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.418     ,  0.24968   , -0.41242   ,  0.1217    ,  0.34527   ,\n",
       "       -0.044457  , -0.49688   , -0.17862   , -0.00066023, -0.6566    ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " ',',\n",
       " '.',\n",
       " 'of',\n",
       " 'to',\n",
       " 'and',\n",
       " 'in',\n",
       " 'a',\n",
       " '\"',\n",
       " \"'s\",\n",
       " 'for',\n",
       " '-',\n",
       " 'that',\n",
       " 'on',\n",
       " 'is',\n",
       " 'was',\n",
       " 'said',\n",
       " 'with',\n",
       " 'he',\n",
       " 'as']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2word[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "عمليات الطرح"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "king - man = queen - woman\n",
      "france - paris = britain - london\n",
      "france - paris = italy - rome\n",
      "paris - france = rome - italy\n",
      "france - french = england - english\n",
      "japan - japanese = china - chinese\n",
      "japan - japanese = italy - italian\n",
      "japan - japanese = australia - australian\n",
      "december - november = july - june\n",
      "miami - florida = houston - texas\n",
      "einstein - scientist = matisse - painter\n",
      "china - rice = chinese - bread\n",
      "man - woman = he - she\n",
      "man - woman = uncle - aunt\n",
      "man - woman = brother - sister\n",
      "man - woman = friend - wife\n",
      "man - woman = actor - actress\n",
      "man - woman = father - mother\n",
      "heir - heiress = queen - princess\n",
      "nephew - niece = uncle - aunt\n",
      "france - paris = japan - tokyo\n",
      "france - paris = china - beijing\n",
      "february - january = october - november\n",
      "france - paris = italy - rome\n",
      "paris - france = rome - italy\n",
      "cairo - egypt = damascus - syria\n"
     ]
    }
   ],
   "source": [
    "find_analogies('king', 'man', 'woman')\n",
    "find_analogies('france', 'paris', 'london')\n",
    "find_analogies('france', 'paris', 'rome')\n",
    "find_analogies('paris', 'france', 'italy')\n",
    "find_analogies('france', 'french', 'english')\n",
    "find_analogies('japan', 'japanese', 'chinese')\n",
    "find_analogies('japan', 'japanese', 'italian')\n",
    "find_analogies('japan', 'japanese', 'australian')\n",
    "find_analogies('december', 'november', 'june')\n",
    "find_analogies('miami', 'florida', 'texas')\n",
    "find_analogies('einstein', 'scientist', 'painter')\n",
    "find_analogies('china', 'rice', 'bread')\n",
    "find_analogies('man', 'woman', 'she')\n",
    "find_analogies('man', 'woman', 'aunt')\n",
    "find_analogies('man', 'woman', 'sister')\n",
    "find_analogies('man', 'woman', 'wife')\n",
    "find_analogies('man', 'woman', 'actress')\n",
    "find_analogies('man', 'woman', 'mother')\n",
    "find_analogies('heir', 'heiress', 'princess')\n",
    "find_analogies('nephew', 'niece', 'aunt')\n",
    "find_analogies('france', 'paris', 'tokyo')\n",
    "find_analogies('france', 'paris', 'beijing')\n",
    "find_analogies('february', 'january', 'november')\n",
    "find_analogies('france', 'paris', 'rome')\n",
    "find_analogies('paris', 'france', 'italy')\n",
    "find_analogies('cairo','egypt','syria')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "الكلمات الاقرب"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbors of: king\n",
      "\tprince\n",
      "\tqueen\n",
      "\tii\n",
      "\temperor\n",
      "\tson\n",
      "neighbors of: france\n",
      "\tfrench\n",
      "\tbelgium\n",
      "\tparis\n",
      "\tspain\n",
      "\tnetherlands\n",
      "neighbors of: japan\n",
      "\tjapanese\n",
      "\tchina\n",
      "\tkorea\n",
      "\ttokyo\n",
      "\ttaiwan\n",
      "neighbors of: einstein\n",
      "\trelativity\n",
      "\tbohr\n",
      "\tphysics\n",
      "\theisenberg\n",
      "\tfreud\n",
      "neighbors of: woman\n",
      "\tgirl\n",
      "\tman\n",
      "\tmother\n",
      "\ther\n",
      "\tboy\n",
      "neighbors of: nephew\n",
      "\tcousin\n",
      "\tbrother\n",
      "\tgrandson\n",
      "\tson\n",
      "\tuncle\n",
      "neighbors of: february\n",
      "\toctober\n",
      "\tdecember\n",
      "\tjanuary\n",
      "\taugust\n",
      "\tseptember\n",
      "neighbors of: rome\n",
      "\tnaples\n",
      "\tvenice\n",
      "\titaly\n",
      "\tturin\n",
      "\tpope\n",
      "neighbors of: bolt\n",
      "\tusain\n",
      "\tjavelin\n",
      "\tkitajima\n",
      "\thammer\n",
      "\trod\n",
      "neighbors of: bus\n",
      "\ttrain\n",
      "\tbuses\n",
      "\tpassenger\n",
      "\tcommuter\n",
      "\ttrains\n",
      "neighbors of: hello\n",
      "\tgoodbye\n",
      "\they\n",
      "\t!\n",
      "\tkiss\n",
      "\twow\n",
      "neighbors of: go\n",
      "\tgoing\n",
      "\tcome\n",
      "\tget\n",
      "\t'll\n",
      "\ttake\n"
     ]
    }
   ],
   "source": [
    "nearest_neighbors('king')\n",
    "nearest_neighbors('france')\n",
    "nearest_neighbors('japan')\n",
    "nearest_neighbors('einstein')\n",
    "nearest_neighbors('woman')\n",
    "nearest_neighbors('nephew')\n",
    "nearest_neighbors('february')\n",
    "nearest_neighbors('rome')\n",
    "\n",
    "nearest_neighbors('bolt')\n",
    "nearest_neighbors('bus')\n",
    "nearest_neighbors('hello')\n",
    "nearest_neighbors('go')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "التجربة علي الملف الأكبر ذو 300 قيمة للتضمين"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in pre-trained word vectors\n",
    "print('Loading word vectors...')\n",
    "word2vec = {}\n",
    "embedding = []\n",
    "idx2word = []\n",
    "\n",
    "with open(r'E:\\Machine Learning\\NLP\\0 Data\\GloVe English\\glove.6B.300d.txt', encoding='utf-8') as f:\n",
    "  # is just a space-separated text file in the format:\n",
    "  # word vec[0] vec[1] vec[2] ...\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vec = np.asarray(values[1:], dtype='float32')\n",
    "        word2vec[word] = vec\n",
    "        embedding.append(vec)\n",
    "        idx2word.append(word)\n",
    "print('Found %s word vectors.' % len(word2vec))\n",
    "embedding = np.array(embedding)\n",
    "V, D = embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "الاطلاع علي البيانات"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for a,b in word2vec.items() : \n",
    "    i+=1\n",
    "    if i==50 : break\n",
    "    print(f'word {a}   ,   with Vecs     {b[:5]}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(embedding[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "عمليات الطرح"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_analogies('king', 'man', 'woman')\n",
    "find_analogies('france', 'paris', 'london')\n",
    "find_analogies('france', 'paris', 'rome')\n",
    "find_analogies('paris', 'france', 'italy')\n",
    "find_analogies('france', 'french', 'english')\n",
    "find_analogies('japan', 'japanese', 'chinese')\n",
    "find_analogies('japan', 'japanese', 'italian')\n",
    "find_analogies('japan', 'japanese', 'australian')\n",
    "find_analogies('december', 'november', 'june')\n",
    "find_analogies('miami', 'florida', 'texas')\n",
    "find_analogies('einstein', 'scientist', 'painter')\n",
    "find_analogies('china', 'rice', 'bread')\n",
    "find_analogies('man', 'woman', 'she')\n",
    "find_analogies('man', 'woman', 'aunt')\n",
    "find_analogies('man', 'woman', 'sister')\n",
    "find_analogies('man', 'woman', 'wife')\n",
    "find_analogies('man', 'woman', 'actress')\n",
    "find_analogies('man', 'woman', 'mother')\n",
    "find_analogies('heir', 'heiress', 'princess')\n",
    "find_analogies('nephew', 'niece', 'aunt')\n",
    "find_analogies('france', 'paris', 'tokyo')\n",
    "find_analogies('france', 'paris', 'beijing')\n",
    "find_analogies('february', 'january', 'november')\n",
    "find_analogies('france', 'paris', 'rome')\n",
    "find_analogies('paris', 'france', 'italy')\n",
    "\n",
    "find_analogies('cairo','egypt','syria')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "الكلمات الاقرب"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_neighbors('king')\n",
    "nearest_neighbors('france')\n",
    "nearest_neighbors('japan')\n",
    "nearest_neighbors('einstein')\n",
    "nearest_neighbors('woman')\n",
    "nearest_neighbors('nephew')\n",
    "nearest_neighbors('february')\n",
    "nearest_neighbors('rome')\n",
    "\n",
    "nearest_neighbors('bolt')\n",
    "nearest_neighbors('bus')\n",
    "nearest_neighbors('hello')\n",
    "nearest_neighbors('go')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
