{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"\"\"\n",
    "Simple example with Cats and Mouse\n",
    "Another simple example with dogs and cats\n",
    "Another simple example with mouse and cheese\n",
    "\"\"\".split(\"\\n\")[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Simple example with Cats and Mouse',\n",
       " 'Another simple example with dogs and cats',\n",
       " 'Another simple example with mouse and cheese']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clearing and tokenizing\n",
    "l_A = corpus[0].lower().split()\n",
    "l_B = corpus[1].lower().split()\n",
    "l_C = corpus[2].lower().split()\n",
    "\n",
    "# Calculating bag of words\n",
    "word_set = set(l_A).union(set(l_B)).union(set(l_C))\n",
    "\n",
    "word_dict_A = dict.fromkeys(word_set, 0)\n",
    "word_dict_B = dict.fromkeys(word_set, 0)\n",
    "word_dict_C = dict.fromkeys(word_set, 0)\n",
    "\n",
    "for word in l_A:\n",
    "    word_dict_A[word] += 1\n",
    "\n",
    "for word in l_B:\n",
    "    word_dict_B[word] += 1\n",
    "\n",
    "for word in l_C:\n",
    "    word_dict_C[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dogs': 0,\n",
       " 'simple': 1,\n",
       " 'cheese': 0,\n",
       " 'cats': 1,\n",
       " 'example': 1,\n",
       " 'with': 1,\n",
       " 'and': 1,\n",
       " 'another': 0,\n",
       " 'mouse': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dict_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tf(word_dict, l):\n",
    "    tf = {}\n",
    "    sum_nk = len(l)\n",
    "    for word, count in word_dict.items():\n",
    "        tf[word] = count/sum_nk\n",
    "    return tf\n",
    "  \n",
    "tf_A = compute_tf(word_dict_A, l_A)\n",
    "tf_B = compute_tf(word_dict_B, l_B)\n",
    "tf_C = compute_tf(word_dict_C, l_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dogs': 0.0,\n",
       " 'simple': 0.16666666666666666,\n",
       " 'cheese': 0.0,\n",
       " 'cats': 0.16666666666666666,\n",
       " 'example': 0.16666666666666666,\n",
       " 'with': 0.16666666666666666,\n",
       " 'and': 0.16666666666666666,\n",
       " 'another': 0.0,\n",
       " 'mouse': 0.16666666666666666}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dogs': 0.14285714285714285,\n",
       " 'simple': 0.14285714285714285,\n",
       " 'cheese': 0.0,\n",
       " 'cats': 0.14285714285714285,\n",
       " 'example': 0.14285714285714285,\n",
       " 'with': 0.14285714285714285,\n",
       " 'and': 0.14285714285714285,\n",
       " 'another': 0.14285714285714285,\n",
       " 'mouse': 0.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dogs': 0.0,\n",
       " 'simple': 0.14285714285714285,\n",
       " 'cheese': 0.14285714285714285,\n",
       " 'cats': 0.0,\n",
       " 'example': 0.14285714285714285,\n",
       " 'with': 0.14285714285714285,\n",
       " 'and': 0.14285714285714285,\n",
       " 'another': 0.14285714285714285,\n",
       " 'mouse': 0.14285714285714285}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dogs': 1.0986122886681098,\n",
       " 'simple': 0.0,\n",
       " 'cheese': 1.0986122886681098,\n",
       " 'cats': 0.4054651081081644,\n",
       " 'example': 0.0,\n",
       " 'with': 0.0,\n",
       " 'and': 0.0,\n",
       " 'another': 0.4054651081081644,\n",
       " 'mouse': 0.4054651081081644}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_idf(strings_list):\n",
    "    n = len(strings_list)\n",
    "    idf = dict.fromkeys(strings_list[0].keys(), 0)\n",
    "    for l in strings_list:\n",
    "        for word, count in l.items():\n",
    "            if count > 0:\n",
    "                idf[word] += 1\n",
    "    \n",
    "    for word, v in idf.items():\n",
    "        idf[word] = np.log(n / float(v))\n",
    "    return idf\n",
    "    \n",
    "idf = compute_idf([word_dict_A, word_dict_B, word_dict_C])\n",
    "idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tf_idf(tf, idf):\n",
    "    tf_idf = dict.fromkeys(tf.keys(), 0)\n",
    "    for word, v in tf.items():\n",
    "        tf_idf[word] = v * idf[word]\n",
    "    return tf_idf\n",
    "    \n",
    "tf_idf_A = compute_tf_idf(tf_A, idf)\n",
    "tf_idf_B = compute_tf_idf(tf_B, idf)\n",
    "tf_idf_C = compute_tf_idf(tf_C, idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dogs': 0.0,\n",
       " 'simple': 0.0,\n",
       " 'cheese': 0.0,\n",
       " 'cats': 0.06757751801802739,\n",
       " 'example': 0.0,\n",
       " 'with': 0.0,\n",
       " 'and': 0.0,\n",
       " 'another': 0.0,\n",
       " 'mouse': 0.06757751801802739}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dogs': 0.15694461266687282,\n",
       " 'simple': 0.0,\n",
       " 'cheese': 0.0,\n",
       " 'cats': 0.05792358687259491,\n",
       " 'example': 0.0,\n",
       " 'with': 0.0,\n",
       " 'and': 0.0,\n",
       " 'another': 0.05792358687259491,\n",
       " 'mouse': 0.0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dogs': 0.0,\n",
       " 'simple': 0.0,\n",
       " 'cheese': 0.15694461266687282,\n",
       " 'cats': 0.0,\n",
       " 'example': 0.0,\n",
       " 'with': 0.0,\n",
       " 'and': 0.0,\n",
       " 'another': 0.05792358687259491,\n",
       " 'mouse': 0.05792358687259491}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "all_text  =  \"\"\"\n",
    " Google and Facebook are strangling the free press to death. Democracy is the loserGoogle an \n",
    "Your 60-second guide to security stuff Google touted today at Next '18\n",
    "A Guide to Using Android Without Selling Your Soul to Google\n",
    "Review: Lenovo’s Google Smart Display is pretty and intelligent\n",
    "Google Maps user spots mysterious object submerged off the coast of Greece - and no-one knows what it is\n",
    "Android is better than IOS\n",
    "In information retrieval, tf–idf or TFIDF, short for term frequency–inverse document frequency\n",
    "is a numerical statistic that is intended to reflect\n",
    "how important a word is to a document in a collection or corpus.\n",
    "It is often used as a weighting factor in searches of information retrieval\n",
    "text mining, and user modeling. The tf-idf value increases proportionally\n",
    "to the number of times a word appears in the document\n",
    "and is offset by the frequency of the word in the corpus\n",
    "\"\"\".split(\"\\n\")[1:-1]\n",
    "\n",
    "# Preprocessing and tokenizing\n",
    "def preprocessing(line):\n",
    "    line = line.lower()\n",
    "    line = re.sub(r\"[{}]\", \" \", line)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eslam\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(preprocessor=preprocessing)\n",
    "tfidf = tfidf_vectorizer.fit_transform(all_text)\n",
    "\n",
    "kmeans = KMeans(n_clusters=2).fit(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lines_for_predicting = [\"tf and idf is awesome!\", \"some androids is there\"]\n",
    "lines_for_predicting = [\"tf and idf is awesome!\", \"Selling Your Soul to Google\"]\n",
    "kmeans.predict(tfidf_vectorizer.transform(lines_for_predicting))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
