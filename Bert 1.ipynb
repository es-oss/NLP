{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "8.6.1 Bert 1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynPRbJviL-39"
      },
      "source": [
        "# NLP with Bert for Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cq0lSGd0ZyDK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad0fe2cc-5ca0-4a43-d5ce-e56a58feeeeb"
      },
      "source": [
        "!pip3 install ktrain"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ktrain\n",
            "  Downloading ktrain-0.27.3.tar.gz (25.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.3 MB 87 kB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.23.2\n",
            "  Downloading scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 35.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from ktrain) (3.2.2)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.1.5)\n",
            "Requirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ktrain) (2.23.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from ktrain) (21.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from ktrain) (5.5.0)\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[K     |████████████████████████████████| 981 kB 37.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jieba in /usr/local/lib/python3.7/dist-packages (from ktrain) (0.42.1)\n",
            "Collecting cchardet\n",
            "  Downloading cchardet-2.1.7-cp37-cp37m-manylinux2010_x86_64.whl (263 kB)\n",
            "\u001b[K     |████████████████████████████████| 263 kB 42.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet in /usr/local/lib/python3.7/dist-packages (from ktrain) (3.0.4)\n",
            "Collecting syntok\n",
            "  Downloading syntok-1.3.1.tar.gz (23 kB)\n",
            "Collecting seqeval==0.0.19\n",
            "  Downloading seqeval-0.0.19.tar.gz (30 kB)\n",
            "Collecting transformers<=4.3.3,>=4.0.0\n",
            "  Downloading transformers-4.3.3-py3-none-any.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 44.9 MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 40.8 MB/s \n",
            "\u001b[?25hCollecting keras_bert>=0.86.0\n",
            "  Downloading keras-bert-0.88.0.tar.gz (26 kB)\n",
            "Requirement already satisfied: networkx>=2.3 in /usr/local/lib/python3.7/dist-packages (from ktrain) (2.6.3)\n",
            "Collecting whoosh\n",
            "  Downloading Whoosh-2.7.4-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[K     |████████████████████████████████| 468 kB 47.9 MB/s \n",
            "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-3.0.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2->ktrain) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2->ktrain) (1.4.1)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.7/dist-packages (from seqeval==0.0.19->ktrain) (2.6.0)\n",
            "Collecting keras-transformer>=0.39.0\n",
            "  Downloading keras-transformer-0.39.0.tar.gz (11 kB)\n",
            "Collecting keras-pos-embd>=0.12.0\n",
            "  Downloading keras-pos-embd-0.12.0.tar.gz (6.0 kB)\n",
            "Collecting keras-multi-head>=0.28.0\n",
            "  Downloading keras-multi-head-0.28.0.tar.gz (14 kB)\n",
            "Collecting keras-layer-normalization>=0.15.0\n",
            "  Downloading keras-layer-normalization-0.15.0.tar.gz (4.2 kB)\n",
            "Collecting keras-position-wise-feed-forward>=0.7.0\n",
            "  Downloading keras-position-wise-feed-forward-0.7.0.tar.gz (4.5 kB)\n",
            "Collecting keras-embed-sim>=0.9.0\n",
            "  Downloading keras-embed-sim-0.9.0.tar.gz (4.1 kB)\n",
            "Collecting keras-self-attention>=0.50.0\n",
            "  Downloading keras-self-attention-0.50.0.tar.gz (12 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (0.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=3.0.0->ktrain) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->ktrain) (2018.9)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 38.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<=4.3.3,>=4.0.0->ktrain) (4.8.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.3.3,>=4.0.0->ktrain) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<=4.3.3,>=4.0.0->ktrain) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.3.3,>=4.0.0->ktrain) (4.62.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 42.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<=4.3.3,>=4.0.0->ktrain) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<=4.3.3,>=4.0.0->ktrain) (3.7.4.3)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain) (57.4.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain) (2.6.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain) (1.0.18)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain) (5.1.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain) (4.8.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ktrain) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->ktrain) (0.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ktrain) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ktrain) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ktrain) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<=4.3.3,>=4.0.0->ktrain) (7.1.2)\n",
            "Building wheels for collected packages: ktrain, seqeval, keras-bert, keras-transformer, keras-embed-sim, keras-layer-normalization, keras-multi-head, keras-pos-embd, keras-position-wise-feed-forward, keras-self-attention, langdetect, syntok\n",
            "  Building wheel for ktrain (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ktrain: filename=ktrain-0.27.3-py3-none-any.whl size=25283131 sha256=b2d0a0000ced872c80c6843c62a30da5a980f554b20050d4bd066d041420329c\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/ef/e1/7da805d8a5944e8a3ac0553831d832c00b1800b848939849cb\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-0.0.19-py3-none-any.whl size=9929 sha256=37d0e82afe12fe2e8c591377724f114858b6b7625447068348eb6715d22af396\n",
            "  Stored in directory: /root/.cache/pip/wheels/f5/ac/f1/4e13d7aff05c722d142b7d20a88ad63f9aab11b895411241a4\n",
            "  Building wheel for keras-bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-bert: filename=keras_bert-0.88.0-py3-none-any.whl size=34204 sha256=2fcd03bb1c4e1c51128a1ce415f8cdc8d32c17c848640a2573d8326fc00066eb\n",
            "  Stored in directory: /root/.cache/pip/wheels/a2/90/cd/c038f2366929a3a5e3414a303b673e10235e802d871d29a835\n",
            "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-transformer: filename=keras_transformer-0.39.0-py3-none-any.whl size=12842 sha256=818950217fadd116ebd326de131631e3083d1882f32e9628f8a68ee27425a2ea\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/01/e0/5a1a14bed6726f2ed73f7917d2d2c2d4081d2c88426dea07ce\n",
            "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.9.0-py3-none-any.whl size=4504 sha256=7c67d15c2dfe7c58dfc46211493ebc8a5b315182c5733d2610b3843bbe35c656\n",
            "  Stored in directory: /root/.cache/pip/wheels/a8/1e/d2/9bc15513dd2f8b9de3e628b3aa9d2de49e721deef6bbd1497e\n",
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.15.0-py3-none-any.whl size=5224 sha256=52b925b372e7f678dd24bd6dd4a928de315023777e16d36c117a945b336485cb\n",
            "  Stored in directory: /root/.cache/pip/wheels/4d/be/fe/55422f77ac11fe6ddcb471198038de8a26b5a4dd1557883c1e\n",
            "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-multi-head: filename=keras_multi_head-0.28.0-py3-none-any.whl size=15559 sha256=5d04d97647b65faac93a272992b5260be498c03c71ba9ebdb52ba50fbf1ae86a\n",
            "  Stored in directory: /root/.cache/pip/wheels/79/4a/ea/9503ab5a02201dfb8635ba2cc8f30844661623c684a5b44472\n",
            "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.12.0-py3-none-any.whl size=7469 sha256=b36304c33003be57fb7470f69dd857fd68108f1980ddd6e500aaee1c700cb92b\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/99/fd/dd98f4876c3ebbef7aab0dbfbd37bca41d7db37d3a28b2cb09\n",
            "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.7.0-py3-none-any.whl size=5541 sha256=83f8b05d5f1d5fe45b7446f01a999e442ddfac2963a4e11e648d075a7b9604db\n",
            "  Stored in directory: /root/.cache/pip/wheels/2d/12/02/1ad455c4f181cda1a4e60c5445855853d5c2ea91f942586a04\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.50.0-py3-none-any.whl size=19414 sha256=3c20d1a6cd03ed8690dcd210205532e0837d0e4b987efaf7f6fae9c18e23d39e\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/7a/a3/231bef5803298e7ec1815215bc0613239cb1e9c03c57b13c14\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=9a7e729fd17468ed9d849103a7e2070134a227131ba89e28dfd845559f588d82\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/96/8a/f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\n",
            "  Building wheel for syntok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for syntok: filename=syntok-1.3.1-py3-none-any.whl size=20917 sha256=09087b59726062d97fc26a04e4aea64117c49be330e6e843cc88f77c5aa4cc18\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/c2/33/e5d7d8f2f8b0c391d76bf82b844c3151bf23a84d75d02b185f\n",
            "Successfully built ktrain seqeval keras-bert keras-transformer keras-embed-sim keras-layer-normalization keras-multi-head keras-pos-embd keras-position-wise-feed-forward keras-self-attention langdetect syntok\n",
            "Installing collected packages: keras-self-attention, keras-position-wise-feed-forward, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-embed-sim, tokenizers, threadpoolctl, sacremoses, keras-transformer, whoosh, transformers, syntok, seqeval, sentencepiece, scikit-learn, langdetect, keras-bert, cchardet, ktrain\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed cchardet-2.1.7 keras-bert-0.88.0 keras-embed-sim-0.9.0 keras-layer-normalization-0.15.0 keras-multi-head-0.28.0 keras-pos-embd-0.12.0 keras-position-wise-feed-forward-0.7.0 keras-self-attention-0.50.0 keras-transformer-0.39.0 ktrain-0.27.3 langdetect-1.0.9 sacremoses-0.0.46 scikit-learn-0.23.2 sentencepiece-0.1.96 seqeval-0.0.19 syntok-1.3.1 threadpoolctl-3.0.0 tokenizers-0.10.3 transformers-4.3.3 whoosh-2.7.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynShOu8nNtFt"
      },
      "source": [
        "import os.path\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import ktrain\n",
        "from ktrain import text"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzRNcHypppou"
      },
      "source": [
        "\n",
        "الان نقوم بتحميل قاعدة البيانات , حيث نستخدم \n",
        "\n",
        "keras \n",
        "\n",
        " لقراءة الملف  \n",
        "\n",
        " aclImdb_v1.tar.gz  \n",
        "\n",
        "والتأكيد علي عمل \n",
        "\n",
        "extract \n",
        "\n",
        "  له , وسيقوم كولاب بتحميل الملف الي الذاكرة المؤقتة له\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kCTV_hjOKmE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d62edc7-4229-4fdf-d4ab-de4314b6531d"
      },
      "source": [
        "dataset = tf.keras.utils.get_file(fname=\"aclImdb_v1.tar.gz\",\n",
        "                                  origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\",\n",
        "                                  extract=True)\n",
        "IMDB_DATADIR = os.path.join(os.path.dirname(dataset), 'aclImdb')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "84131840/84125825 [==============================] - 2s 0us/step\n",
            "84140032/84125825 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5Z8RoF_qicp"
      },
      "source": [
        "و يمكن استعراض الملفات داخلها هكذا "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ATyK7XNqaGw",
        "outputId": "739d2c1f-5243-4456-c2fc-ca235d420776"
      },
      "source": [
        "os.listdir(IMDB_DATADIR)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['README', 'imdbEr.txt', 'train', 'test', 'imdb.vocab']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psarRHLRqdzw",
        "outputId": "84666915-bc91-4fb6-ae9d-94d9048cbf69"
      },
      "source": [
        "os.listdir(os.path.join(IMDB_DATADIR , 'train'))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['unsup',\n",
              " 'urls_pos.txt',\n",
              " 'urls_unsup.txt',\n",
              " 'labeledBow.feat',\n",
              " 'unsupBow.feat',\n",
              " 'neg',\n",
              " 'urls_neg.txt',\n",
              " 'pos']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_BHIT0iqfqj",
        "outputId": "d54c91ee-5f3e-413d-f7e3-69ccd25e29ef"
      },
      "source": [
        "os.listdir(os.path.join(IMDB_DATADIR , 'train','pos'))[:10]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['2334_9.txt',\n",
              " '151_10.txt',\n",
              " '11661_7.txt',\n",
              " '2511_10.txt',\n",
              " '11807_7.txt',\n",
              " '7539_10.txt',\n",
              " '7727_9.txt',\n",
              " '705_10.txt',\n",
              " '6509_9.txt',\n",
              " '3872_9.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avEK_WWyVlgy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fded120-1d17-4f6a-d2d8-e3ba73ae22f2"
      },
      "source": [
        "print(os.path.dirname(dataset))\n",
        "print(IMDB_DATADIR)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/.keras/datasets\n",
            "/root/.keras/datasets/aclImdb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3QIL9TXqkQq"
      },
      "source": [
        "كما يمكن قراءة احد الملفات هكذا"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhCBvVeVql07",
        "outputId": "caf99821-af0f-4d98-8d27-c38f121d96d5"
      },
      "source": [
        "f= open(os.path.join(IMDB_DATADIR , 'train','pos','5035_7.txt'),'r')\n",
        "for a in f:\n",
        "    print(a)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "McConaughey in a horror/thriller? I had to see this. I was pleasantly surprised.<br /><br />The plot is told in flashback mode, and it concerns an otherwise normal and happy family of three going through a very bizarre predicament. I can't say much more without spoiling the whole movie, sorry. Just know that if you decide to watch it, you'll be, in the very least, surprised.<br /><br />All the main players are very good. Bill Paxton did a great job directing those kids, and his acting is awesome. McConaughey's acting is solid throughout and fits the bill perfectly.<br /><br />This movie challenges you to think. Is Dad crazy? Is there a God? Do Demons exist? How far would you go to right a wrong. And what is \"right\" anyway? I'm still thinking.<br /><br />And thus I recommend \"Frailty\". 7/10 and this is one of those movies that deserves and rewards a second, or even third viewing.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Up68JocOq2V6"
      },
      "source": [
        "الان نقوم بقراءة الداتا و تقسيمها , و ذلك عبر استخدام مكتبة كيترين   و التي ستقرأ الملفات من المسار الموضح,  ثم يتم كتابة اسماء النوعين \"ايجابي\" , \"سلبي\", ثم تحديد ان العدد الاقصي للكلمات المستخدمة هو 500 , وتحديد اسم التدريب و الاختبار, واخيرا تحديد نوع المعالجة التي ستتناول بها الكلمات وهو بيرت"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_v1UUUg1hY4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "cccd8fb9-4dd7-45bf-c543-bcb5125ffc1c"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test), preproc = text.texts_from_folder(datadir=IMDB_DATADIR,\n",
        "                                                                       classes=['pos','neg'],\n",
        "                                                                       maxlen=500,\n",
        "                                                                       train_test_names=['train','test'],\n",
        "                                                                       preprocess_mode='bert')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "detected encoding: utf-8\n",
            "downloading pretrained BERT model (uncased_L-12_H-768_A-12.zip)...\n",
            "[██████████████████████████████████████████████████]\n",
            "extracting pretrained BERT model...\n",
            "done.\n",
            "\n",
            "cleanup downloaded zip...\n",
            "done.\n",
            "\n",
            "preprocessing train...\n",
            "language: en\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "done."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing test...\n",
            "language: en\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "done."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8erCUYATr6HW"
      },
      "source": [
        "الان لخطوة بناء الموديل , و التي تتم عبر  كتابة الكود  : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ec0gNVP9s--C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4af79ded-e69a-4761-d604-4eb0ff0e1d65"
      },
      "source": [
        "model = text.text_classifier(name='bert',\n",
        "                             train_data=(x_train, y_train),\n",
        "                             preproc=preproc)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is Multi-Label? False\n",
            "maxlen is 500\n",
            "done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AHFA6fasF49"
      },
      "source": [
        "  \n",
        "فنقوم بتحديد اسم الموديل المختار , ثم بيانات التدريب , و اخيرا المعالج المستخدم  , والذي سيكون نفسه بريبروك  و الذي خرج من الكود السابق \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpN107mIsMmU"
      },
      "source": [
        "الان في مرحلة ضبط خصائص الـ ليرنز  و هي اشبه بخطوة كومبايل في الشبكات العصبية, حيث نقوم بضبط الخصائص قبل التدريب"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voHx9EOPvSb1"
      },
      "source": [
        "learner = ktrain.get_learner(model=model,\n",
        "                             train_data=(x_train, y_train),\n",
        "                             val_data=(x_test, y_test),\n",
        "                             batch_size=6)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxVxCq9gsbWP"
      },
      "source": [
        "مع العلم ان الرقم الباتش لابد ان تتناسب عكسيا مع ال ماكس لين  فكلما زادت عدد كلمات كل جملة  ,يجب ان تقل الباتش  و هنا القيم المسموح بها : "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1oL7JfssbRb"
      },
      "source": [
        "sequence len=64, max_batch_size=64\n",
        "\n",
        "sequence len=128, max_batch_size=32\n",
        "\n",
        "sequence len=256, max_batch_size=16\n",
        "\n",
        "sequence len=320, max_batch_size=14\n",
        "\n",
        "sequence len=384, max_batch_size=12\n",
        "\n",
        "sequence len=512, max_batch_size=6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_NBHWVesrb0"
      },
      "source": [
        "الان خطوة التدريب  نستخدم معها معدل تعلم صغير , ويكفي ايبوك واحد لانه سيكون بطئ جدا و خلال هذا الايبوك ستزداد الدقة بشكل كبير"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVfEfoRuxWSe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee99bf3f-7644-40c5-f85d-1b92ea4d22b7"
      },
      "source": [
        "learner.fit_onecycle(lr=2e-5,\n",
        "                     epochs=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 2e-05...\n",
            "4167/4167 [==============================] - ETA: 0s - loss: 0.2479 - accuracy: 0.8976"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPRD6pd4s8uG"
      },
      "source": [
        "ثم خطوة التوقع , والتي ستكون باستخدام دالة التوقع"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdvmPqMmstDq"
      },
      "source": [
        "y_pred = learner.predict(val_data=(x_test[:100],y_test[:100]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scB6x9JmtAl6"
      },
      "source": [
        "وقتها تكون القيمة هكذا"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZmSlb7Tsy0m"
      },
      "source": [
        "y_pred[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3WcKeGzs4Bp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}